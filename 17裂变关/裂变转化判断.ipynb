{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 零基础实战机器学习\n",
    "\n",
    "## 第17讲 集成学习-裂变转化预测\n",
    "\n",
    "作者 黄佳\n",
    "\n",
    "极客时间专栏链接：https://time.geekbang.org/column/intro/438\n",
    "\n",
    "\n",
    "问题：通过集成学习方法预测用户是否会购买促销品\n",
    "\n",
    "易速鲜花公司推出两张促销方案，分别是疯狂打折和买一送一。\n",
    "\n",
    "通过集成学习方法，我们可以预测出用户是否会购买这些打折商品。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #导入Pandas\n",
    "import numpy as np #导入NumPy\n",
    "df_fission = pd.read_csv('易速鲜花裂变转化.csv') #载入数据\n",
    "print('用户数:', df_fission.count()['用户码']) #查看数据条目数\n",
    "df_fission #显示头几行数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把二元类别文本数字化\n",
    "df_fission['性别'].replace(\"女\",0,inplace = True)\n",
    "df_fission['性别'].replace(\"男\",1,inplace=True)\n",
    "# 显示数字类别\n",
    "print(\"Gender unique values\",df_fission['性别'].unique())\n",
    "# 把多元类别转换成多个二元哑变量，然后贴回原始数据集\n",
    "df_fission = pd.get_dummies(df_fission, drop_first = True)\n",
    "# df_fission = [df_fission, d_city]\n",
    "# df_fission = pd.concat(df_bank, axis = 1)\n",
    "# 构建特征和标签集合\n",
    "# y = df_fission['Exited']\n",
    "# X = df_fission.drop(['Name', 'Exited', 'City'], axis=1)\n",
    "# X.head() #显示新的特征集\n",
    "df_fission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt #导入pyplot模块\n",
    "import seaborn as sns #导入Seaborn\n",
    "fig = sns.countplot(x='是否转化', data=df_fission) #创建柱状计数图\n",
    "# fig.set_xticklabels(fig.get_xticklabels(),rotation=25) #X轴标签倾斜\n",
    "fig.set_ylabel(\"数目\") #Y轴标题\n",
    "plt.show() #显示图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建特征和标签数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fission = df_fission.query(\"裂变类型 == '助力砍价'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_fission.drop(['用户码','是否转化'], axis = 1) # 构建特征集\n",
    "y = df_fission.是否转化.values # 构建标签集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler #导入归一化缩放器\n",
    "scaler = MinMaxScaler() #创建归一化缩放器\n",
    "X_train = scaler.fit_transform(X_train) #拟合并转换训练集数据\n",
    "X_test = scaler.transform(X_test) #转换测试集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix # 导入混淆矩阵\n",
    "import seaborn as sns #导入seaborn画图工具箱\n",
    "def show_matrix(y_test, y_pred): # 定义一个函数显示混淆矩阵\n",
    "    cm = confusion_matrix(y_test,y_pred) # 调用混淆矩阵\n",
    "    plt.title(\"混淆矩阵\") # 标题\n",
    "    sns.heatmap(cm,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False) # 热力图设定\n",
    "    plt.show() # 显示混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对多棵决策树进行聚合(Bagging)\n",
    "from sklearn.ensemble import BaggingClassifier # 导入Bagging 分类器\n",
    "from sklearn.tree import DecisionTreeClassifier # 导入决策树分类器\n",
    "from sklearn.metrics import (f1_score, confusion_matrix) # 导入评估指标\n",
    "dt = BaggingClassifier(DecisionTreeClassifier()) # 只使用一棵决策树\n",
    "dt.fit(X_train, y_train) # 拟合模型\n",
    "y_pred = dt.predict(X_test) # 进行预测\n",
    "print(\" 决策树测试准确率: {:.2f}%\".format(dt.score(X_test, y_test)*100))\n",
    "print(\" 决策树测试F1 分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))\n",
    "bdt = BaggingClassifier(DecisionTreeClassifier()) # 树的Bagging\n",
    "bdt.fit(X_train, y_train) # 拟合模型\n",
    "y_pred = bdt.predict(X_test) # 进行预测\n",
    "print(\" 决策树Bagging 测试准确率: {:.2f}%\".format(bdt.score(X_test, y_test)*100))\n",
    "print(\" 决策树Bagging 测试F1 分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))\n",
    "show_matrix(y_test, y_pred)\n",
    "f1_bdt = f1_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV # 导入网格搜索工具\n",
    "from sklearn.ensemble import RandomForestClassifier # 导入随机森林模型\n",
    "rf = RandomForestClassifier() # 随机森林模型\n",
    "rf.fit(X_train, y_train) # 拟合模型\n",
    "y_pred = rf.predict(X_test) # 进行预测\n",
    "print(\" 随机森林测试准确率: {:.2f}%\".format(rf.score(X_test, y_test)*100))\n",
    "print(\" 随机森林测试F1 分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))\n",
    "show_matrix(y_test, y_pred)\n",
    "f1_rf = f1_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier # 导入极端随机森林模型\n",
    "ext = ExtraTreesClassifier() # 极端随机森林模型\n",
    "ext.fit(X_train, y_train) # 拟合模型\n",
    "y_pred = ext.predict(X_test) # 进行预测\n",
    "print(\" 极端随机森林测试准确率: {:.2f}%\".format(ext.score(X_test, y_test)*100))\n",
    "print(\" 极端随机森林测试F1 分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))\n",
    "show_matrix(y_test, y_pred)\n",
    "f1_ext = f1_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier # 导入AdaBoost 模型\n",
    "dt = DecisionTreeClassifier() # 选择决策树分类器作为AdaBoost 的基准算法\n",
    "ada = AdaBoostClassifier(dt) # AdaBoost 模型\n",
    "ada.fit(X_train, y_train) # 拟合模型\n",
    "y_pred = ada.predict(X_test) # 进行预测\n",
    "print(\"AdaBoost 测试准确率: {:.2f}%\".format(ada.score(X_test, y_test)*100))\n",
    "print(\"AdaBoost 测试F1 分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))\n",
    "show_matrix(y_test, y_pred)\n",
    "f1_ada = f1_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier # 导入梯度提升模型\n",
    "gb = GradientBoostingClassifier() # 梯度提升模型\n",
    "gb.fit(X_train, y_train) # 拟合模型\n",
    "y_pred = gb.predict(X_test) # 进行预测\n",
    "print(\" 梯度提升测试准确率: {:.2f}%\".format(gb.score(X_test, y_test)*100))\n",
    "print(\" 梯度提升测试F1 分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))\n",
    "show_matrix(y_test, y_pred)\n",
    "f1_gb = f1_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier # 导入XGB 模型\n",
    "xgb = XGBClassifier() # XGB 模型\n",
    "xgb.fit(X_train, y_train) # 拟合模型\n",
    "y_pred = xgb.predict(X_test) # 进行预测\n",
    "print(\"XGB 测试准确率: {:.2f}%\".format(xgb.score(X_test, y_test)*100))\n",
    "print(\"XGB 测试F1 分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))\n",
    "show_matrix(y_test, y_pred)\n",
    "f1_xgb = f1_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier # 导入XGB 模型\n",
    "# xgb = XGBClassifier() # XGB 模型\n",
    "# # 使用网格搜索优化参数\n",
    "# xgb_param_grid = {'min_child_weight': [1, 5, 10],\n",
    "# 'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "# 'subsample': [0.6, 0.8, 1.0],\n",
    "# 'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "# 'max_depth': [3, 4, 5]}\n",
    "# xgb_gs = GridSearchCV(xgb, param_grid = xgb_param_grid,\n",
    "# scoring=\"f1\", n_jobs= 10, verbose = 1)\n",
    "# xgb_gs.fit(X_train, y_train) # 拟合模型\n",
    "# xgb_gs = xgb_gs.best_estimator_ # 最佳模型\n",
    "# y_pred = xgb_gs.predict(X_test) # 进行预测\n",
    "# print(\"XGB 测试准确率: {:.2f}%\".format(xgb_gs.score(X_test, y_test)*100))\n",
    "# print(\"XGB 测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))\n",
    "# show_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier # 导入Voting 模型\n",
    "# 把各种模型的预测结果进行Voting。同学们还可以加入更多模型如SVM, KNN 等\n",
    "voting = VotingClassifier(estimators=[('rf', rf),('bdt', bdt),('gb', gb),\n",
    "                                      ('ext', ext),('xgb', xgb),('ada', ada)],\n",
    "voting='soft', n_jobs=10)\n",
    "voting = voting.fit(X_train, y_train) # 拟合模型\n",
    "y_pred = voting.predict(X_test) # 进行预测\n",
    "print(\"Voting 测试准确率: {:.2f}%\", voting.score(X_test, y_test)*100)\n",
    "print(\"Voting 测试F1分数: {:.2f}%\", f1_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV # 导入网格搜索工具\n",
    "# from sklearn.ensemble import RandomForestClassifier # 导入随机森林模型\n",
    "# rf = RandomForestClassifier() # 随机森林模型\n",
    "# # 使用网格搜索优化参数\n",
    "# rf_param_grid = {\"max_depth\": [None],\n",
    "# \"max_features\": [1, 3, 10],\n",
    "# \"min_samples_split\": [2, 3, 10],\n",
    "# \"min_samples_leaf\": [1, 3, 10],\n",
    "# \"bootstrap\": [True, False],\n",
    "# \"n_estimators\" :[100, 300],\n",
    "# \"criterion\": [\"gini\"]}\n",
    "# rf_gs = GridSearchCV(rf, param_grid = rf_param_grid,\n",
    "# scoring=\"f1\", n_jobs= 10, verbose = 1)\n",
    "# rf_gs.fit(X_train, y_train) # 拟合模型\n",
    "# rf_gs = rf_gs.best_estimator_ # 最佳模型\n",
    "# y_pred = rf_gs.predict(X_test) # 进行预测\n",
    "# print(\"调优后随机森林测试准确率: {:.2f}%\".format(rf_gs.score(X_test, y_test)*100))\n",
    "# print(\"调优后随机森林测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train).astype(np.float32)\n",
    "X_test = np.asarray(X_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras # 导入Keras库\n",
    "from keras.models import Sequential # 导入Keras序贯模型\n",
    "from keras.layers import Dense # 导入Keras密集连接层\n",
    "ann = Sequential() # 创建一个序贯ANN模型\n",
    "ann.add(Dense(units=12, input_dim=11, activation = 'relu')) # 添加输入层\n",
    "ann.add(Dense(units=24, activation = 'relu')) # 添加隐层\n",
    "ann.add(Dense(units=48, activation = 'relu')) # 添加隐层\n",
    "ann.add(Dense(units=1, activation = 'sigmoid')) # 添加输出层\n",
    "ann.summary() # 显示网络模型（这个语句不是必须的）\n",
    "# 编译神经网络，指定优化器，损失函数，以及评估标准\n",
    "ann.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['acc'])\n",
    "history = ann.fit(X_train, y_train, # 指定训练集\n",
    "                  epochs=30,        # 指定训练的轮次\n",
    "                  batch_size=64,    # 指定数据批量\n",
    "                  validation_split=0.2) #指定验证集,这里为了简化模型，直接用训练集数据\n",
    "# show_history(history) # 调用这个函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann.predict(X_test,batch_size=10) # 预测测试集的标签\n",
    "y_pred = np.round(y_pred) # 将分类概率值转换成0/1整数值\n",
    "print(\"神经网络测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签\n",
    "# plt.rcParams['axes.unicode_minus']=False #用来正常显示负号\n",
    "# plt.rcParams[\"font.family\"]=['SimHei']\n",
    "methods = [\"树的Bagging\", \"随机森林\", \"极端随机森林\",\n",
    "\"AdaBoost\", \"GBDT\", \"XGBoost\"]\n",
    "f1 = [f1_bdt, f1_rf, f1_ext, f1_ada, f1_gb, f1_xgb]\n",
    "colors = [\"orange\", \"red\", \"purple\", \"magenta\", \"green\", \"blue\"]\n",
    "# sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.yticks(np.arange(0, 100, 10))\n",
    "plt.ylabel(\"F1分数\")\n",
    "plt.xlabel(\"算法\")\n",
    "sns.barplot(x=methods, y=f1, palette=colors)\n",
    "# plt.grid(b=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machlearn",
   "language": "python",
   "name": "machlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 零基础实战机器学习\n",
    "\n",
    "## 第15讲 会员流失情况判断\n",
    "\n",
    "作者 黄佳\n",
    "\n",
    "极客时间专栏链接：https://time.geekbang.org/column/intro/438\n",
    "\n",
    "\n",
    "问题：判断易速鲜花会员的是否会流失情况\n",
    "\n",
    "易速鲜花公司拥有多年的会员记录，以及会员停止续费的情况。\n",
    "\n",
    "通过逻辑回归和神经网络等机器学习模型，我们可以判断出客户是否离开，这是一个典型的的二元分类问题。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据的读入和预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # 导入NumPy\n",
    "import pandas as pd # 导入Pandas\n",
    "import matplotlib.pyplot as plt # 导入matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_member = pd.read_csv('易速鲜花会员留存.csv') # 导入数据包\n",
    "df_member #显示数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把总消费字段转换成数值字段\n",
    "df_member['总消费'] = pd.to_numeric(df_member['总消费'], errors='coerce')\n",
    "df_member['总消费'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(2, 2, 1)\n",
    "ax = df_member.groupby('性别').count()['用户码'].plot.pie(autopct='%1.0f%%') #饼图\n",
    "plt.subplot(2, 2, 2)\n",
    "ax = df_member.groupby('会费支付方式').count()['用户码'].plot.pie(autopct='%1.0f%%') #饼图\n",
    "plt.subplot(2, 2, 3)\n",
    "ax = df_member.groupby('会员卡类型').count()['用户码'].plot.pie(autopct='%1.0f%%') #饼图\n",
    "plt.subplot(2, 2, 4)\n",
    "ax = df_member.groupby('已停付会费').count()['用户码'].plot.pie(autopct='%1.0f%%') #饼图\n",
    "plt.show() #显示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_member['已停付会费'].replace(to_replace='是', value=1, inplace=True) #流失-1\n",
    "df_member['已停付会费'].replace(to_replace='否',  value=0, inplace=True) #未流失-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_member['性别'].replace(to_replace='女', value=0, inplace=True) #女生-0\n",
    "df_member['性别'].replace(to_replace='男', value=1, inplace=True) #男生-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字段中'Yes' or 'No'转换成为模型可以读取的数值,（布尔型数据，也是数值数据）\n",
    "binary_features = ['玫瑰套餐', '紫罗兰套餐', '郁金香套餐', '百合套餐', '康乃馨套餐', '胡姬花套餐', \n",
    "                   '生日套餐','情人节套餐']\n",
    "for field in binary_features:\n",
    "    df_member[field] = df_member[field] == '是'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_member"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据整理\n",
    "先做数据整理工作，把每个数据字段都转换为可以处理的字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 分类字段哑变量\n",
    "category_features = ['会员卡类型', '会费支付方式']\n",
    "df_member = pd.get_dummies(df_member, drop_first=True, columns=category_features)\n",
    "df_member"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建特征集和标签集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_member.drop(['用户码','已停付会费'], axis = 1) # 构建特征集，用户码字段属于无用特征\n",
    "y = df_member.已停付会费.values # 构建标签集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拆分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #导入train_test_split模块\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2) #拆分数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择算法\n",
    "\n",
    "这里我们比较逻辑回归和神经网络两种算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逻辑回归模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression #导入逻辑回归模型\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000) # lr,就代表是逻辑回归模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练机器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train,y_train) # fit,就相当于是梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SK-learn逻辑回归预测准确率{:.2f}%\".format(lr.score(X_test,y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=lr.predict(X_test)\n",
    "print(\"逻辑回归对测试集第一个用户的预测结果\", y_pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras # 导入Keras库\n",
    "from keras.models import Sequential # 导入Keras序贯模型\n",
    "from keras.layers import Dense # 导入Keras密集连接层\n",
    "dnn = Sequential() # 创建一个序贯DNN模型\n",
    "dnn.add(Dense(units=12, input_dim=17, activation = 'relu')) # 添加输入层\n",
    "dnn.add(Dense(units=24, activation = 'relu')) # 添加隐层\n",
    "dnn.add(Dense(units=1, activation = 'sigmoid')) # 添加输出层\n",
    "dnn.summary() # 显示网络模型（这个语句不是必须的）\n",
    "# 编译神经网络，指定优化器，损失函数，以及评估标准\n",
    "dnn.compile(optimizer = 'RMSProp', #优化器\n",
    "            loss = 'binary_crossentropy', #损失函数\n",
    "            metrics = ['acc']) #评估标准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape #X_train目前的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train).astype(np.float32) # 转换为NumPy张量\n",
    "X_test = np.asarray(X_test).astype(np.float32) # 转换为NumPy张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtype #X_train转换后的类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = dnn.fit(X_train, y_train, # 指定训练集\n",
    "                  epochs=30,        # 指定训练的轮次\n",
    "                  batch_size=64,    # 指定数据批量\n",
    "                  validation_split=0.2) #这里直接从训练集数据中拆分验证集，更方便"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_history(history): # 显示训练过程中的学习曲线\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_history(history) # 调用这个函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dnn.evaluate(X_test, y_test) #评估测试集上的准确率\n",
    "print('DNN的测试准确率为',\"{0:.2f}%\".format(result[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = dnn.predict(X_test) #预测测试集的图片分类\n",
    "print('第一个用户分类结果为:', np.argmax(prediction[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络模型-归一化之后"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.asarray(X_train).astype(np.float32)\n",
    "# X_test = np.asarray(X_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler #导入归一化缩放器\n",
    "scaler = MinMaxScaler() #创建归一化缩放器\n",
    "X_train = scaler.fit_transform(X_train) #拟合并转换训练集数据\n",
    "X_test = scaler.transform(X_test) #转换测试集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = dnn.fit(X_train, y_train, # 指定训练集\n",
    "                  epochs=30,        # 指定训练的轮次\n",
    "                  batch_size=64,    # 指定数据批量\n",
    "                  validation_split=0.2) #指定验证集,这里为了简化模型，直接用训练集数据\n",
    "show_history(history) # 调用这个函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dnn.evaluate(X_test, y_test) #评估测试集上的准确率\n",
    "print('DNN（归一化之后）的测试准确率为',\"{0:.2f}%\".format(result[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machlearn",
   "language": "python",
   "name": "machlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
